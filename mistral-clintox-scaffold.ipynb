{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet deepchem rdkit transformers accelerate bitsandbytes peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T22:47:41.471889Z","iopub.execute_input":"2026-02-16T22:47:41.472212Z","iopub.status.idle":"2026-02-16T22:47:52.718880Z","shell.execute_reply.started":"2026-02-16T22:47:41.472183Z","shell.execute_reply":"2026-02-16T22:47:52.717881Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.4/552.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.7/36.7 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install --quiet trl datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T22:48:01.681830Z","iopub.execute_input":"2026-02-16T22:48:01.682195Z","iopub.status.idle":"2026-02-16T22:48:06.386666Z","shell.execute_reply.started":"2026-02-16T22:48:01.682158Z","shell.execute_reply":"2026-02-16T22:48:06.385551Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.5/540.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os, gc, torch, numpy as np, pandas as pd\nimport deepchem as dc\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\nfrom sklearn.metrics import roc_auc_score\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nfrom rdkit import Chem\n\n# clear vram\ntorch.cuda.empty_cache()\ngc.collect()\n\n# --- 1. DATA LOAD (Direct download to bypass deepchem loader issues) ---\nprint(\"Fetching ClinTox csv...\")\ntry:\n    # try direct link first\n    df = pd.read_csv(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/clintox.csv.gz\")\nexcept:\n    # fallback local\n    print(\"Download failed, using local file...\")\n    df = pd.read_csv(\"clintox.csv.gz\")\n\nprint(f\"Raw rows: {len(df)}\")\n\n# Sanitize SMILES - drop anything RDKit hates\nvalid_idxs = []\nfor idx, row in df.iterrows():\n    try:\n        mol = Chem.MolFromSmiles(row['smiles'])\n        if mol: valid_idxs.append(idx)\n    except: pass\n\ndf_clean = df.iloc[valid_idxs].reset_index(drop=True)\nprint(f\"Valid rows: {len(df_clean)}\")\n\n# --- 2. SCAFFOLD SPLIT ---\nprint(\"Running scaffold split...\")\n# Target columns: FDA_APPROVED, CT_TOX\ndataset = dc.data.NumpyDataset(\n    X=df_clean['smiles'].values, \n    y=df_clean[['FDA_APPROVED', 'CT_TOX']].values, \n    ids=df_clean['smiles'].values\n)\nsplitter = dc.splits.ScaffoldSplitter()\ntrain_dc, valid_dc, test_dc = splitter.train_valid_test_split(dataset)\n\nprint(f\"Train: {len(train_dc)}, Test: {len(test_dc)}\")\n\n# --- 3. DATASET CLASS & AUGMENTATION ---\ndef random_smiles(smiles):\n    try:\n        mol = Chem.MolFromSmiles(smiles)\n        if not mol: return smiles\n        return Chem.MolToSmiles(mol, doRandom=True, canonical=False)\n    except: return smiles\n\nclass ClinToxDataset(Dataset):\n    def __init__(self, dc_data, tokenizer, max_len=256, augment=False):\n        self.data = []\n        self.tokenizer = tokenizer\n        \n        ids = dc_data.ids # smiles strings\n        y = dc_data.y     # [fda, tox]\n        \n        indices = list(range(len(ids)))\n        \n        # Heavy upsampling for toxic class (imbalance fix)\n        if augment:\n            tox_idxs = [i for i in indices if y[i][1] == 1]\n            # x5 multiplier for minority class\n            indices += tox_idxs * 5 \n            np.random.shuffle(indices)\n\n        for i in indices:\n            smi_canon = str(ids[i])\n            \n            # Focus on CT_TOX (index 1)\n            label = int(y[i][1]) \n            label_str = \"Yes\" if label == 1 else \"No\"\n            \n            smi_variants = [smi_canon]\n            \n            # Add noise (random smiles) for training toxic samples\n            if augment and label == 1: \n                for _ in range(2):\n                    smi_variants.append(random_smiles(smi_canon))\n            \n            for smi in smi_variants:\n                # Prompt format\n                txt = f\"Task: Clinical Toxicity | SMILES: {smi} | Toxic: {label_str}\" + tokenizer.eos_token\n                \n                enc = tokenizer(\n                    txt, \n                    max_length=max_len, \n                    padding=\"max_length\", \n                    truncation=True, \n                    return_tensors=\"pt\"\n                )\n                self.data.append({\n                    \"ids\": enc[\"input_ids\"][0],\n                    \"mask\": enc[\"attention_mask\"][0],\n                    \"label\": label\n                })\n\n    def __len__(self): return len(self.data)\n    def __getitem__(self, idx): return self.data[idx]\n\n# --- 4. MODEL SETUP ---\nprint(\"Loading Mistral-7B...\")\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True\n)\n\nmodel_id = \"mistralai/Mistral-7B-v0.1\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)\n\npeft_config = LoraConfig(\n    r=16, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"], \n    lora_dropout=0.05, bias=\"none\", task_type=TaskType.CAUSAL_LM\n)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()\n\n# --- 5. TRAINING ---\ntrain_ds = ClinToxDataset(train_dc, tokenizer, augment=True)\ntest_ds = ClinToxDataset(test_dc, tokenizer, augment=False)\ntrain_loader = DataLoader(train_ds, batch_size=2, shuffle=True)\n\nopt = torch.optim.AdamW(model.parameters(), lr=1e-4) # low lr for stability\n\nEPOCHS = 3\nACCUM_STEPS = 8 \n\nprint(f\"Starting loop ({EPOCHS} epochs)...\")\nbest_score = 0.0\n\nfor epoch in range(EPOCHS):\n    model.train()\n    epoch_loss = 0\n    pbar = tqdm(train_loader, desc=f\"Ep {epoch+1}\")\n    \n    for step, batch in enumerate(pbar):\n        ids = batch[\"ids\"].to(\"cuda\")\n        mask = batch[\"mask\"].to(\"cuda\")\n        \n        out = model(input_ids=ids, attention_mask=mask, labels=ids)\n        loss = out.loss / ACCUM_STEPS\n        loss.backward()\n        \n        if (step + 1) % ACCUM_STEPS == 0:\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n            opt.step()\n            opt.zero_grad()\n            \n        epoch_loss += loss.item() * ACCUM_STEPS\n        pbar.set_postfix({\"loss\": f\"{epoch_loss/(step+1):.4f}\"})\n\n    # Validate\n    print(\"Validating...\")\n    model.eval()\n    preds, acts = [], []\n    id_yes = tokenizer.encode(\"Yes\", add_special_tokens=False)[0]\n    id_no = tokenizer.encode(\"No\", add_special_tokens=False)[0]\n    \n    with torch.no_grad():\n        for item in tqdm(test_ds.data, desc=\"Testing\"):\n            full_txt = tokenizer.decode(item[\"ids\"], skip_special_tokens=True)\n            # split at prompt end\n            query = full_txt.split(\"Toxic:\")[0] + \"Toxic:\"\n            \n            inp = tokenizer(query, return_tensors=\"pt\").to(\"cuda\")\n            out = model(**inp)\n            logits = out.logits[0, -1, [id_no, id_yes]]\n            probs = torch.nn.functional.softmax(logits.float(), dim=-1)\n            \n            preds.append(probs[1].item())\n            acts.append(item[\"label\"])\n            \n    auc = roc_auc_score(acts, preds)\n    print(f\"Epoch {epoch+1} ROC-AUC: {auc:.4f}\")\n    \n    if auc > 0.94:\n        print(f\"High score ({auc:.4f}), saving adapter...\")\n        model.save_pretrained(f\"mistral_clintox_epoch_{epoch+1}\")\n        best_score = auc\n\nprint(f\"Best Score: {best_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T22:48:08.882885Z","iopub.execute_input":"2026-02-16T22:48:08.883273Z","iopub.status.idle":"2026-02-17T01:01:28.077426Z","shell.execute_reply.started":"2026-02-16T22:48:08.883239Z","shell.execute_reply":"2026-02-17T01:01:28.076675Z"}},"outputs":[{"name":"stderr","text":"2026-02-16 22:48:20.499597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771282100.740486      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771282100.811037      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771282101.412889      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771282101.412956      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771282101.412963      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771282101.412968      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","output_type":"stream"},{"name":"stdout","text":"WARNING:tensorflow:From /usr/local/lib/python3.12/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\nInstructions for updating:\nexperimental_relax_shapes is deprecated, use reduce_retracing instead\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","output_type":"stream"},{"name":"stdout","text":"Fetching ClinTox csv...\nRaw rows: 1484\n","output_type":"stream"},{"name":"stderr","text":"[22:48:48] Explicit valence for atom # 0 N, 4, is greater than permitted\n[22:48:48] Can't kekulize mol.  Unkekulized atoms: 9\n[22:48:48] Can't kekulize mol.  Unkekulized atoms: 4\n[22:48:48] Can't kekulize mol.  Unkekulized atoms: 4\n","output_type":"stream"},{"name":"stdout","text":"Valid rows: 1480\nRunning scaffold split...\nTrain: 1184, Test: 148\nLoading Mistral-7B...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aa4a8932a5a400c872e3f941d43cfc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"943d91adc9b64df0912625efae19e7b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d464a9180d6e404cb4c6cc771b031d4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a342b8e9cf0b4bd5b04d5915d5584acb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75064e75af0143a9beb8dcd644df642c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ccea1095936467db2f02b1db3382b65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a2329dccf440e3a99c70b43c623cc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fa9d9c906cf4f6cb13c552551f36eb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"600deafa44fe4d52a6dcb74ba1430aa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9e0627f51484e74a89186514ff50309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"012cb804e08841268b955c3f2dfc3cb1"}},"metadata":{}},{"name":"stdout","text":"trainable params: 13,631,488 || all params: 7,255,363,584 || trainable%: 0.1879\nStarting loop (3 epochs)...\n","output_type":"stream"},{"name":"stderr","text":"Ep 1:   0%|          | 0/1400 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\nEp 1: 100%|██████████| 1400/1400 [43:04<00:00,  1.85s/it, loss=5.7488]\n","output_type":"stream"},{"name":"stdout","text":"Validating...\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 148/148 [00:32<00:00,  4.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 ROC-AUC: 0.9768\nHigh score (0.9768), saving adapter...\n","output_type":"stream"},{"name":"stderr","text":"Ep 2:   0%|          | 0/1400 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\nEp 2: 100%|██████████| 1400/1400 [43:14<00:00,  1.85s/it, loss=5.6603]\n","output_type":"stream"},{"name":"stdout","text":"Validating...\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 148/148 [00:32<00:00,  4.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 ROC-AUC: 0.9913\nHigh score (0.9913), saving adapter...\n","output_type":"stream"},{"name":"stderr","text":"Ep 3:   0%|          | 0/1400 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\nEp 3: 100%|██████████| 1400/1400 [43:14<00:00,  1.85s/it, loss=5.6288]\n","output_type":"stream"},{"name":"stdout","text":"Validating...\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 148/148 [00:32<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 ROC-AUC: 0.9877\nHigh score (0.9877), saving adapter...\nBest Score: 0.9877\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}